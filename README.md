# OSE Project

ðŸŽ¯ **Goal**: Classify companies as "Good Business Opportunity" vs "Not Good Opportunity" by combining article text analysis with company features using sklearn Pipeline.

## ðŸ“ Project Structure

```
ose-main/
â”œâ”€â”€ Notebooks/
â”‚   â””â”€â”€ 01_dataset_visualization_v2.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ose_core/
â”‚       â”œâ”€â”€ config/
â”‚       â”œâ”€â”€ data/
â”‚       â”‚   â””â”€â”€ extracted_datasets/
â”‚       â”œâ”€â”€ feature_engineering/
â”‚       â”œâ”€â”€ mlops/
â”‚       â”œâ”€â”€ model/
â”‚       â”œâ”€â”€ scoring/
â”‚       â””â”€â”€ utils/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_data.py
â”‚   â”œâ”€â”€ test_feature_engineering.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_scoring.py
â”œâ”€â”€ QUICK_SETUP.md
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ Makefile
```

## ðŸš€ Setup Instructions

### Python 3.10 Environment Setup (pyenv)

#### ðŸ“‹ Prerequisites

Ensure you have `pyenv` installed. If not, install it:

**macOS (via Homebrew):**
```bash
brew install pyenv
```

**Linux:**
Follow the [pyenv installation guide](https://github.com/pyenv/pyenv#installation)

---

#### 1ï¸âƒ£ Quick Setup (Recommended)

```bash
# Run the setup Makefile target (does everything automatically)
make setup
```

This will:
- Install Python 3.10.6 (if not already installed)
- Create virtualenv named `ose-env`
- Upgrade pip
- Install all project requirements
- Register Jupyter kernel

---

#### 2ï¸âƒ£ Manual Setup (Alternative)

If you prefer to set up manually:

```bash
# Install Python 3.10.6 (if not already installed)
pyenv install -s 3.10.6

# Create virtualenv named ose-env
pyenv virtualenv 3.10.6 ose-env

# Activate the environment
pyenv activate ose-env

# Upgrade pip first
python -m pip install --upgrade pip

# Install project requirements
pip install -r requirements.txt

# Register kernel for Jupyter (named ose-env)
python -m ipykernel install --user --name ose-env --display-name "Python (ose-env)"
```

---

#### 3ï¸âƒ£ Verify Installation

Run the verification command:

```bash
# Quick verification using Makefile
make verify
```

Or verify manually:

```bash
# Verify Python version
python -V  # Should show Python 3.10.x

# Verify all imports work
python -c "import pandas, sklearn, xgboost, keras, tensorflow, shap; print('âœ“ All imports OK')"

# Verify sklearn components
python -c "from sklearn.pipeline import Pipeline; from sklearn.impute import SimpleImputer, KNNImputer; from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder; from sklearn.decomposition import PCA; from sklearn.cluster import KMeans; from sklearn.neighbors import NearestNeighbors; print('âœ“ sklearn components OK')"

# Verify Keras
python -c "from keras.layers import Normalization; print('âœ“ Keras OK')"

# Verify Jupyter kernel
jupyter kernelspec list  # Should show Python (ose-env)
```

---

#### 5ï¸âƒ£ Run the Notebook

Open and run the notebook:

```bash
jupyter notebook notebooks/05_business_opportunity_classifier.ipynb
```

> **Note:** Make sure to select the "Python (ose-env)" kernel in Jupyter.

## ðŸ“¦ Key Components

- **`Notebooks/`** - Jupyter notebooks for data visualization and analysis
- **`src/ose_core/`** - Core project modules:
  - `data/` - Data loading utilities and extracted datasets
  - `config/` - Configuration files
  - `feature_engineering/` - Feature engineering modules
  - `model/` - Model definitions and training
  - `scoring/` - Scoring and evaluation modules
  - `mlops/` - MLOps utilities
  - `utils/` - Utility functions
- **`tests/`** - Unit tests for all modules
- **`requirements.txt`** - Python dependencies

## Key Features

- âœ… sklearn Pipeline with ColumnTransformer for mixed data types
- âœ… Pipeline visualization using sklearn's diagram display
- âœ… Text features from article titles (TF-IDF)
- âœ… Company features (financial, workforce, structure, flags, contacts)
- âœ… Binary classification with comprehensive evaluation
- âœ… Top 10 companies ranked by opportunity score

## Data Extraction Pipeline

- The fast extraction pipeline lives in `src/ose_core/pipelines/` and mirrors the v3.1 workflow from `_Data_Extract_Viz_agro`.
- It produces the 9 datasets consumed by `DataLoader` (`src/ose_core/data`), preserving the same schema (`company_name`, `siren`, `siret` + dataset-specific columns).
- Default settings live in `src/ose_core/config/extraction_config.yaml` (chunk size, output directory, dataset names).
- Example usage is available in `Notebooks/00_data_extraction.ipynb`:
  - set JSONL input paths (`company`, `article`, `project`)
  - run `make_extract_pipeline(...)`
  - save with `save_datasets_to_dir(...)` to `src/ose_core/data/extracted_datasets/`

## Business Logic

- Positive signals: Investissements, Recrutement, Construction, LevÃ©e de fonds
- Negative signals: Vente & Cession, RJ & LJ, Restructuration, Licenciement
- Target: Good opportunity if (positive > negative) OR (positive >= 2)

